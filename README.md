ğŸ¥ AI Meeting Summarizer (Audio + Video + Visual Understanding)

An AI-powered web application that automatically transcribes, summarizes, and analyzes meetings from audio and video files.
For video uploads, the system goes beyond audio by understanding visual content such as presentation slides (PPT), on-screen text, and objects, and generates a combined intelligent summary.

ğŸš€ Features
ğŸ”Š Audio-Based Intelligence

Upload audio files (.mp3, .wav, .m4a)

Accurate speech-to-text transcription using Whisper

Concise meeting summary generation using Transformer-based NLP models

ğŸ¥ Video-Based Multimodal Intelligence

When a video file (.mp4) is uploaded, the system performs multimodal analysis:

Audio Extraction

Extracts audio track from video using FFmpeg

Converts speech to text using Whisper ASR

Visual Understanding

Extracts key video frames at fixed intervals

Detects:

ğŸ“Š Presentation slides (PPT)

ğŸ§¾ On-screen text (via OCR)

ğŸ–¼ Objects & scenes

Text & Object Detection

Uses OCR to read visible slide text

Uses image captioning models to describe visual content

Combined AI Summary

Generates:

Speech summary (what was said)

Visual summary (what was shown)

Final combined summary (audio + visuals)

ğŸ§  How It Works (Pipeline)
ğŸ“Œ Audio Upload
Audio File
   â†“
Whisper ASR
   â†“
Transcript
   â†“
Text Summarization (BART)

ğŸ“Œ Video Upload
Video File
   â†“
Audio Extraction (FFmpeg) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“                              â”‚
Whisper ASR                        â”‚
   â†“                              â”‚
Speech Summary                     â”‚
                                   â†“
Frame Extraction (OpenCV)
   â†“
OCR + Image Captioning
   â†“
Visual Summary
   â†“
Combined AI Summary

ğŸ§° Tech Stack
ğŸ”™ Backend

Python

Flask â€“ Web framework

ğŸ§  AI / ML

Whisper (faster-whisper) â€“ Speech-to-Text

BART (facebook/bart-large-cnn) â€“ Text summarization

BLIP â€“ Image captioning (visual understanding)

EasyOCR â€“ Slide & on-screen text detection

ğŸ¥ Video & Image Processing

FFmpeg â€“ Audio extraction from video

OpenCV â€“ Frame extraction

Pillow â€“ Image handling

ğŸ¨ Frontend

HTML5

Tailwind CSS

JavaScript

ğŸ“ Supported File Formats
Type	Formats
Audio	.mp3, .wav, .m4a, .aac
Video	.mp4, .webm, .mov
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/ai-meeting-summarizer.git
cd ai-meeting-summarizer

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate   # Linux / Mac
.venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install flask werkzeug faster-whisper transformers torch torchvision
pip install opencv-python pillow easyocr

4ï¸âƒ£ Install FFmpeg

Windows: https://ffmpeg.org/download.html

Linux:

sudo apt install ffmpeg

5ï¸âƒ£ Run the App
python app.py


Open browser:

http://localhost:5000

ğŸ–¥ Application Pages

ğŸ  Home â€“ Upload audio/video and view summary

ğŸ’¬ Chat â€“ Ask questions about the meeting using AI

â„¹ï¸ About â€“ Project overview and technical details

ğŸ“Š Output Example (Video Upload)

Transcript

Full text of spoken conversation from the video

Speech Summary

Key discussion points extracted from audio

Visual Summary

Detected slides, charts, titles, and on-screen content

Combined Summary

Unified understanding of what was said and what was shown

ğŸ”® Future Enhancements

Speaker diarization (who spoke when)

Sentiment analysis of meetings

Auto slide-to-summary mapping

Cloud deployment & multi-user support

Meeting action-item extraction

ğŸ‘¨â€ğŸ’» Author

Aditya Kaper
B.E. Computer Science
AI & Full-Stack Development Enthusiast

â­ Why This Project Matters

This project demonstrates real-world multimodal AI by combining:

Speech Recognition

Computer Vision

Natural Language Processing

It solves a practical productivity problem by converting long meetings into actionable insights
